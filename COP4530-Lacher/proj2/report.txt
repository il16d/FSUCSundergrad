COP 4530 Project 2
Using a Trojan Horse Comparion Operator to Analyze Algorithm Runtimes
Iho Lopez Tobi
lopeztob
il16d

1. Let f(n) = n (n + 1) / 2. Of the following possibilities, state which are true
about f and of those, which one best describes the asymptotic class of f ? 

a.  Θ(n2)       	        b.  O(n2)    	       	        c.  Ω(n2)
d.  Θ(n (n + 1) / 2)    	e.  O(n (n + 1) / 2)		f.  Ω(n (n + 1) / 2) 
g.  Θ(n3)                       h.  O(n3)	         	i.  Ω(n3)
j.  Θ(n log n)	                k.  O(n log n)	                l.  Ω(n log n)
m.  Θ(n)                        n.  O(n)	        	o.  Ω(n)

Answer:
	It would be easier to prove by contradiction because most of the
	possibilities are true.  
Proof by Contradiction:
        
Definitions:
Big O:
g(n) <= O(f(n)) iff there exist positive constants c and n0 such that 0 <= g(n)
	<= cf(n) for all n >= n0

Big Omega:
g(n) >= Ω(f(n)) iff there exist positive constants c and n0 such that 0 <= cf(n)
	<= g(n) for all n >= n0

Big Theta:
g(n) = Θ(f(n)) iff there exist positive constants c1, c2, and n0 such that 0 <=
	c1f(n) <= g(n) <= c2f(n) for all n >= n0
     

	     f(n) = n (n + 1) / 2 = n^2 + n / 2; So F(n) is O(n^2)

	      By definition of Big Theta and Big Omega 
              O(n^3) ≥ n^2 !≥ Ω(n3)
	      Thus g and i are false.

              By definition of Big Theta and Big O
	      Ω(n log n) ≤ n^2 !≤ O(n log n) 
	      Thus j and k are false.

	      By definition of Big Theta and Big O
	      Ω(n) ≤ n^2 !≤ O(n)         
	      Thus m and n are false.

	      Therefore by contradiction of g, i, j, k, m, and n being false
	      a, b, c, d, e, f, h, i, and o are true. qed	


Out of the above selections, the best asymptotic class of f is O(n^2) because it
approaches the curve similarly to n(n + 1)/2.


2. Which of these statements are best supported by data obtained using search_spy
(argue your answer):

a. fsu::g_lower_bound has asymptotic runtime Θ(log n).
b. fsu::g_lower_bound has asymptotic runtime O(log n) but not Ω(log n).
c. seq::g_lower_bound has asymptotic runtime Θ(n).
d. seq::g_lower_bound has asymptotic runtime O(n) but not Ω(n).

Answer:
	a, because fsu uses binary search is in order of O(log n) as the 1/2 of the
	possible entries are eliminated each iteration.
	
	d, because seq uses sequential search and there is the possibility of
	early bail out but most of the time it will belong to the O(n) class
	needing n comparisons where n = dataset size.


3. State an asymptotic runtime for each sort algorithm that is best supported by
data gathered with sort_spy. Argue your answer using collected data, and also
discuss characteristics of the algorithm body that support your answer.

g_selection_sort            = Θ(n^2)
g_insertion_sort            ≤ O(n^2)
g_heap_sort                 ≤ O(n log n)
List::Sort (insertion sort) ≤ O(n^2) 

g_selection sort  = Θ(n^2)
	   The selection sort algorthm requires the comparison of each element
	   in the list with every other element in the list to obtain a minimum
	   value and than move that minimum value to the end of the sorted
	   portion of the list.  Keeping in mind as the new minimum value is
	   found and moved the unsorted portion of the list size shrinks.
	   For example:

 Input file name: n.10
            size: 10

           algorithm     comp_count         n   n log n    n(n+1)/2
           ---------     ----------       ---   -------    --------
    g_selection_sort             55        10        33          55


           By this data selection sort takes 55 comparisons to sort a list of 10
           items which is 10+9+...+2+1 = 55
	   	 Thus: Selection sort = (n-0)+(n-1)+(n-2)+...+(n-n)
	   This summation can be simplified to n(n+1)/2 = n^2/2 + n/2
	   Therefore as the data set increases the n^2 is going to be the
           dominating factor so selection sort is in the order of, or worst case
           performance of O(n^2).  Supposing Selection sort was ran on an
           already sorted list it would still require iterations through the
           entire list to check if a minimum value needs to be moved, so best
           case performance of Ω(n^2)     
	   Concluding that selection sort has an asymptotic run time of Θ(n^2).


g_inserstion sort  ≤ O(n^2)
	   The insertion sort algorithm requires an iteration through each
	   element in the unsorted portion which has the posibility of inserting
	   a new item at the begining of the sorted portion each time, which
	   would require iterating through the sorted portion as well.  
           So, 1(comparison for first element),2(comparisons for the second)...
 	       1+2+ ... + n-1 ; where n is the length of the list.
	   This summation can be simplified to n(n-1)/2 = n^2/2 - n/2
	   
	   The data below shows that g_insertion_sort is a little more than
	   half of selection sort or n(n+1)/2.

	  
           algorithm     comp_count      n   n log n    n(n+1)/2
           ---------     ----------     ---   -------    --------
        g_insertion_sort     2685       100       664        5050


	   As the data set increases the n^2 is going to be the dominating
	   factor so insertion sort is in the order of O(n^2). However there is
	   the possibility of running insertion sort on a sorted list which
	   would be on the order of n or Ω(n) because the sorted list would only need to
	   iterate n times.
	     Thus insertion sort has an asymptotic run time of ≤ O(n^2).        
	     
g_heap_sort ≤ O(n log n)
	   Heap sort algorithm is a sophisticated sorting system, by copying the
	   array into a heap space and assigning 2 child elements for every
	   parent elements, than compare each child to its parent (starting at
	   the last child) and swaping if the child is larger than its parent.
	   Once the heap is in sorted order with the largest element at the root
	   the root is placed into the end of array or list and the last child
	   element is swaped to the root while deleting the last elements
	   position.  The heap must be updated once again and than repeat the
	   proccess of insert into array and delete last child element.  This is
	   done until no items are left in the heap.      

	   The following data shows that g_heap_sort ran with an input data set
	   of 10, 100, and 1000 comeing in just over n log n comparisons 

           algorithm     comp_count         n   n log n    n(n+1)/2
           ---------     ----------       ---   -------    --------
         g_heap_sort             40        10        33          55
         g_heap_sort          17254      1000      9965      500500
         g_heap_sort           1040       100       664        5050

	 Thus we could say that heap sort is in the order or worst case of
	 O(n log n) and best case of Ω(n log n) because even if heap sort
	 sorted array was used on a sorted array it would still need to make
	 roughly n log n comparisons.  Therefore heap sort has an asymptotic run
	 time of ≤ O(n log n).

List::Sort = ≤ O(n^2) 
	   In this excersize List::Sort is Insertion sort.  


4. Describe two scenarios, one under which the namespace fsu search algorithms
are appropriate and one under which the namespace seq versions are appropriate.

It is obvious that namespace fsu is the fastest due to binary search cutting
search space in half on each iteration, however the data must be sorted first in
order to properly use binary search.  Thus I suppose the best reason to use seq
version would be in a small such as 10 element array, vector, or deque.     
